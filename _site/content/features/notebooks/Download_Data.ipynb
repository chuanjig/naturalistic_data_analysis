{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Localizer Data\n",
    "\n",
    "Many of the imaging tutorials will use open data from the Pinel Localizer task.\n",
    "\n",
    "The Pinel Localizer task was designed to probe several different types of basic cognitive processes, such as visual perception, finger tapping, language, and math. Several of the tasks are cued by reading text on the screen (i.e., visual modality) and also by hearing auditory instructions (i.e., auditory modality). The trials are randomized across conditions and have been optimized to maximize efficiency for a rapid event related design. There are 100 trials in total over a 5-minute scanning session. Read the [paper](https://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-8-91) for more specific details about the task. You can also view the [Data](http://brainomics.cea.fr/localizer/dataset?rql=Any%20X%2C%20XT%2C%20XL%2C%20XI%2C%20XF%2C%20XD%20WHERE%20X%20is%20Scan%2C%20X%20type%20XT%2C%20X%20label%20XL%2C%20X%20identifier%20XI%2C%20X%20format%20XF%2C%20X%20description%20XD) on the authorâ€™s cubicweb interface.\n",
    "\n",
    "This dataset is well suited for these tutorials as it is (a) publicly available to anyone in the world, (b) relatively small (only about 5min), and (c) provides many options to create different types of contrasts.\n",
    "\n",
    "There are a total of 94 subjects available, but we will primarily only be working with a smaller subset of about 30.\n",
    "\n",
    "Downloading the data is very easy.  All we need to do is specify a directory to download and unpack it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:11:49.684964Z",
     "start_time": "2019-06-21T03:11:49.682172Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltools.data import Brain_Data\n",
    "from nltools.datasets import fetch_localizer\n",
    "\n",
    "data_dir = '/Users/lukechang/nilearn_data/brainomics_localizer/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first will create a list of subject identification numbers from 's01' to 's30'.  Then we will download all of the subjects one by one using the `fetch_localizer` function from `nltools.datasets`.  You can easily modify this code to download more or less subjects.\n",
    "\n",
    "We can choose to download either the 'raw' or 'preprocessed' data. Feel free to download both, but you will have to change the `data_type` and rerun the function. \n",
    "\n",
    "We can also choose if we want to download the anatomical images. This is useful for running preprocessing later. \n",
    "\n",
    "If you are eager to get going and don't plan on preprocessing the data yourself, feel free to set `get_anats=False, data_type='preprocessed'` to download the bare minimum. \n",
    "\n",
    "Don't forget to set `data_dir=data_dir` if you want to put the data in a specific folder.  Otherwise it will default to `~/nilearn_data/brainomics_localizer/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T02:58:26.599807Z",
     "start_time": "2019-06-21T02:58:22.494501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://brainomics.cea.fr/localizer/dataset/cubicwebexport.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloaded 1555 of 1555 bytes (100.0%,    0.0s remaining) ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://brainomics.cea.fr/localizer/dataset/cubicwebexport2.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloaded 64001 of 64001 bytes (100.0%,    0.0s remaining) ...done. (4 seconds, 0 min)\n"
     ]
    }
   ],
   "source": [
    "sub_ids = [f'S{x:02}' for x in np.arange(1,31)]\n",
    "\n",
    "f = fetch_localizer(subject_ids=sub_ids, get_anats=True, data_type='raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have now downloaded all of the data!\n",
    "\n",
    "The `f` variable contains a dictionary of all of the relevant data.  \n",
    "\n",
    " - `f['functional']`: contains a list of the functional data.\n",
    " - `f['structural']`: contains a list of the structural data.\n",
    " - `f['ext_vars']`: contains all of the subject metadata\n",
    " - `f['description']`: contains a brief description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:10:15.455729Z",
     "start_time": "2019-06-21T03:10:15.452764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brainomics Localizer\n",
      "\n",
      "\n",
      "Notes\n",
      "-----\n",
      "A protocol that captures the cerebral bases of auditory and\n",
      "visual perception, motor actions, reading, language comprehension\n",
      "and mental calculation at an individual level. Individual functional\n",
      "maps are reliable and quite precise.\n",
      "\n",
      "\n",
      "Content\n",
      "-------\n",
      "    :'func': Nifti images of the neural activity maps\n",
      "    :'cmaps': Nifti images of contrast maps\n",
      "    :'tmaps': Nifti images of corresponding t-maps\n",
      "    :'masks': Structural images of the mask used for each subject.\n",
      "    :'anats': Structural images of anatomy of each subject\n",
      "\n",
      "References\n",
      "----------\n",
      "For more information about this dataset's structure:\n",
      "http://brainomics.cea.fr/localizer/\n",
      "\n",
      "To cite this dataset:\n",
      "Papadopoulos Orfanos, Dimitri, et al.\n",
      "\"The Brainomics/Localizer database.\"\n",
      "NeuroImage 144.B (2017): 309.\n",
      "\n",
      "For an example of scientific results obtained using this dataset:\n",
      "Pinel, Philippe, et al.\n",
      "\"Fast reproducible identification and large-scale databasing of\n",
      " individual functional cognitive networks.\"\n",
      "BMC Neuroscience 8.1 (2007): 91.\n",
      "\n",
      "Licence: usage is unrestricted for non-commercial research purposes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f['description'].decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look inside the metadata file.\n",
    "\n",
    "It is a pandas data frame with info about each participant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['ext_vars'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's try to load one of the functional datasets using `Brain_Data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:13:02.267571Z",
     "start_time": "2019-06-21T03:13:01.739486Z"
    }
   },
   "outputs": [
    {
     "ename": "DimensionError",
     "evalue": "Input data has incompatible dimensionality: Expected dimension is 4D and you provided a 5D image. See http://nilearn.github.io/manipulating_images/input_output.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDimensionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-d493f847f938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBrain_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'functional'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nltools-0.3.13-py3.6.egg/nltools/data/brain_data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, Y, X, mask, output_file, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                 self.data.append(self.nifti_masker.fit_transform(\n\u001b[0;32m--> 132\u001b[0;31m                                                  nib.load(i)))\n\u001b[0m\u001b[1;32m    133\u001b[0m                             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNifti1Image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnifti_masker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, confounds, **fit_params)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                 ).transform(X, confounds=confounds)\n\u001b[1;32m    206\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, imgs, confounds)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_single_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nilearn/input_data/nifti_masker.py\u001b[0m in \u001b[0;36mtransform_single_imgs\u001b[0;34m(self, imgs, confounds, copy)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mconfounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         )\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nilearn/input_data/nifti_masker.py\u001b[0m in \u001b[0;36mfilter_and_mask\u001b[0;34m(imgs, mask_img_, parameters, memory_level, memory, verbose, confounds, copy, dtype)\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     dtype=None):\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matleast_4d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Check whether resampling is truly necessary. If so, crop mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDimensionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDimensionError\u001b[0m: Input data has incompatible dimensionality: Expected dimension is 4D and you provided a 5D image. See http://nilearn.github.io/manipulating_images/input_output.html."
     ]
    }
   ],
   "source": [
    "data = Brain_Data(f['functional'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh, oh...  Looks like this data was created using an older version of SPM and isn't being read correctly by `Brain_Data`.\n",
    "\n",
    "Let's do our first bit of debugging and fix this.\n",
    "\n",
    "We will use nibabel to load the data and inspect the shape of the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:15:27.802236Z",
     "start_time": "2019-06-21T03:15:27.796985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 40, 1, 128)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "dat = nib.load(f['functional'][0][0])\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:15:09.655027Z",
     "start_time": "2019-06-21T03:15:09.651482Z"
    }
   },
   "source": [
    "The first 3 dimensions correspond to X, Y, & Z planes.  The last dimension is time. It looks like there is an extra dimension that we will need to get rid of so that we can load the data correctly.\n",
    "\n",
    "We will get the data into a numpy array and use the `squeeze()` method to collapse the extra dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:17:29.952788Z",
     "start_time": "2019-06-21T03:17:29.948462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 40, 128)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.get_data().squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how we now have the correct shape?\n",
    "\n",
    "Let's now create a new nibabel instance with the correct dimensions and write over the file.\n",
    "\n",
    "To create a new nibabel instance, we just need to pass in the 4-D numpy array with the affine matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:18:48.308755Z",
     "start_time": "2019-06-21T03:18:48.304968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.,   0.,   0.,  96.],\n",
       "       [  0.,   3.,   0., -96.],\n",
       "       [  0.,   0.,   3., -60.],\n",
       "       [  0.,   0.,   0.,   1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:20:32.565226Z",
     "start_time": "2019-06-21T03:20:30.690938Z"
    }
   },
   "outputs": [],
   "source": [
    "dat_fixed = nib.Nifti1Image(dat.get_data().squeeze(), dat.affine)\n",
    "nib.save(dat_fixed, f['functional'][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:20:03.003481Z",
     "start_time": "2019-06-21T03:20:02.999758Z"
    }
   },
   "source": [
    "Let's check and see if we can correctly load the file now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:22:08.071038Z",
     "start_time": "2019-06-21T03:21:49.779000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltools.data.brain_data.Brain_Data(data=(128, 238955), Y=0, X=(0, 0), mask=MNI152_T1_2mm_brain_mask.nii.gz, output_file=[])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Brain_Data(f['functional'][0])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:21:19.464074Z",
     "start_time": "2019-06-21T03:21:19.459770Z"
    }
   },
   "source": [
    "Great!  Looks like we fixed it.  Let's now fix all of the rest of the images so that we won't have this problem again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:26:00.348893Z",
     "start_time": "2019-06-21T03:25:27.759495Z"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in f['functional']:\n",
    "    dat = nib.load(file_name[0])\n",
    "    if len(dat.shape) > 4:\n",
    "        dat_fixed = nib.Nifti1Image(dat.get_data().squeeze(), dat.affine)\n",
    "        nib.save(dat_fixed, file_name[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
