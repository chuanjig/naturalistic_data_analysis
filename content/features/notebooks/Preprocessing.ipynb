{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Preprocessing\n",
    "*Written by Luke Chang*\n",
    "\n",
    "There are currently no agreed upon conventions for preprocessing naturalistic neuroimaging data. In this tutorial, we show how we preprocessed the datasets used in all of our tutorials. This tutorial assumes you have some basic knowledge of preprocessing. If you have questions about the specific details, we enourage you to read other tutorials, such as the preprocessing [overview](https://dartbrains.org/features/notebooks/7_Preprocessing.html) from the Dartbrains course. Various contributors also share their personal thoughts on issues they consider in their own labs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturalistic Data Preprocessing\n",
    "For the two datasets we are using in this course (Sherlock & Paranoia), we performed very minimal preprocessing. First, we used [fmriprep](https://fmriprep.readthedocs.io/en/stable/) to realign and spatially normalize the data. If you don't have strong opinions about the details of preprocessing, we highly recommend using fmriprep, which is developed and maintained by a team at the [Center for Reproducible Research](http://reproducibility.stanford.edu/) led by Russ Poldrack and Chris Gorgolewski. Fmriprep was designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols, requires minimal user input, and provides easily interpretable and comprehensive error and output reporting. We like that they share a docker container with all of the relevant software packages, it is very simple to run, and that there is a large user base that actively report bugs so that it is constantly improving.\n",
    "\n",
    "After preprocessing with fmriprep, we smoothed the data (fwhm=6mm) and performed basic voxelwise denoising using a GLM. This entails including the 6 realignment parameters, their squares, their derivatives, and squared derivatives. We also include dummy codes for spikes identified from global signal outliers and outliers identified from frame differencing (i.e., temporal derivative). We chose to not perform high-pass filtering and instead include linear & quadratic trends, and average CSF activity to remove additional physiological and scanner artifacts. Finally, to save space, we downsampled to Float32 precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltools.stats import regress, zscore\n",
    "from nltools.data import Brain_Data, Design_Matrix\n",
    "from nltools.stats import find_spikes \n",
    "from nltools.mask import expand_mask\n",
    "\n",
    "def make_motion_covariates(mc, tr):\n",
    "    z_mc = zscore(mc)\n",
    "    all_mc = pd.concat([z_mc, z_mc**2, z_mc.diff(), z_mc.diff()**2], axis=1)\n",
    "    all_mc.fillna(value=0, inplace=True)\n",
    "    return Design_Matrix(all_mc, sampling_freq=1/tr)\n",
    "\n",
    "base_dir = '/Volumes/Engram/Data/Sherlock/fmriprep'\n",
    "\n",
    "fwhm=6\n",
    "tr = 1.5\n",
    "outlier_cutoff = 3\n",
    "\n",
    "file_list = [x for x in glob.glob(os.path.join(base_dir, '*/func/*preproc*gz')) if 'denoised' not in x] \n",
    "for f in file_list:\n",
    "    sub = os.path.basename(f).split('_')[0]\n",
    "\n",
    "    data = Brain_Data(f)\n",
    "    smoothed = data.smooth(fwhm=fwhm)\n",
    "\n",
    "    spikes = smoothed.find_spikes(global_spike_cutoff=outlier_cutoff, diff_spike_cutoff=outlier_cutoff)\n",
    "    covariates = pd.read_csv(glob.glob(os.path.join(base_dir, sub, 'func', '*tsv'))[0], sep='\\t')\n",
    "    mc = covariates[['trans_x','trans_y','trans_z','rot_x', 'rot_y', 'rot_z']]\n",
    "    mc_cov = make_motion_covariates(mc, tr)\n",
    "    csf = covariates['csf'] # Use CSF from fmriprep output\n",
    "    dm = Design_Matrix(pd.concat([csf, mc_cov, spikes.drop(labels='TR', axis=1)], axis=1), sampling_freq=1/tr)\n",
    "    dm = dm.add_poly(order=2, include_lower=True) # Add Intercept, Linear and Quadratic Trends\n",
    "\n",
    "    smoothed.X = dm\n",
    "    stats = smoothed.regress()\n",
    "    stats['residual'].data = np.float32(stats['residual'].data) # cast as float32 to reduce storage space\n",
    "    stats['residual'].write(os.path.join(base_dir, sub, 'func', f'{sub}_denoise_smooth{fwhm}mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also saved the cropped denoised viewing data as an hdf5 file to speed up loading times when using nltools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T03:33:26.139279Z",
     "start_time": "2020-06-08T03:30:20.233843Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukechang/anaconda3/lib/python3.7/site-packages/deepdish/io/hdf5io.py:251: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  elif _pandas and isinstance(level, (pd.DataFrame, pd.Series, pd.Panel)):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b58ed4fa33be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBrain_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{f.split('.nii.gz')[0]}.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltools-0.3.20-py3.7.egg/nltools/data/brain_data.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_name, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;34m'mask_file_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;34m'file_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             }, compression=kwargs.get('compression', 'blosc'))\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_nifti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/deepdish/io/hdf5io.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(path, data, compression)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                 _save_level(h5file, group, value, name=key,\n\u001b[0;32m--> 584\u001b[0;31m                             filters=filters, idtable=idtable)\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         elif (_sns and isinstance(data, SimpleNamespace) and\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/deepdish/io/hdf5io.py\u001b[0m in \u001b[0;36m_save_level\u001b[0;34m(handler, group, level, name, filters, idtable)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0m_save_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_pandas\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPanel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/deepdish/io/hdf5io.py\u001b[0m in \u001b[0;36m_save_ndarray\u001b[0;34m(handler, group, name, x, filters)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_attrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_attrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitemsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tables/array.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnparr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;31m# Then, try with a point-wise selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tables/array.py\u001b[0m in \u001b[0;36m_write_slice\u001b[0;34m(self, startl, stopl, stepl, shape, nparr)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mnparr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnparr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mcountl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopl\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartl\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_write_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnparr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_write_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnparr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir = '/Volumes/Engram/Data/Sherlock/fmriprep'\n",
    "\n",
    "for scan in ['Part1', 'Part2']:\n",
    "    file_list = glob.glob(os.path.join(data_dir, '*', 'func', f'*crop*{scan}*nii.gz'))\n",
    "    for f in file_list:\n",
    "        data = Brain_Data(f)\n",
    "        data.write(f\"{f.split('.nii.gz')[0]}.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have also precomputed average activations within a whole brain parcellation (n=50) for some of the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T04:17:17.821438Z",
     "start_time": "2020-06-08T03:55:43.603710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01\n",
      "sub-02\n",
      "sub-03\n",
      "sub-04\n",
      "sub-05\n",
      "sub-06\n",
      "sub-07\n",
      "sub-08\n",
      "sub-09\n",
      "sub-10\n",
      "sub-11\n",
      "sub-12\n",
      "sub-13\n",
      "sub-14\n",
      "sub-15\n",
      "sub-16\n",
      "sub-01\n",
      "sub-02\n",
      "sub-03\n",
      "sub-04\n",
      "sub-05\n",
      "sub-06\n",
      "sub-07\n",
      "sub-08\n",
      "sub-09\n",
      "sub-10\n",
      "sub-11\n",
      "sub-12\n",
      "sub-13\n",
      "sub-14\n",
      "sub-15\n",
      "sub-16\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Volumes/Engram/Data/Sherlock/fmriprep'\n",
    "\n",
    "mask = Brain_Data('http://neurovault.org/media/images/2099/Neurosynth%20Parcellation_0.nii.gz')\n",
    "\n",
    "for scan in ['Part1', 'Part2']:\n",
    "    file_list = glob.glob(os.path.join(data_dir, '*', 'func', f'*crop*{scan}*hdf5'))\n",
    "    for f in file_list:\n",
    "        sub = os.path.basename(f).split('_')[0]\n",
    "        print(sub)\n",
    "        data = Brain_Data(f)\n",
    "        roi = data.extract_roi(mask)\n",
    "        pd.DataFrame(roi.T).to_csv(os.path.join(os.path.dirname(f), f\"{sub}_{scan}_Average_ROI_n50.csv\" ), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contributors' Opinions on Preprocessing\n",
    "\n",
    "## Luke Chang\n",
    "In our work, we perform standard realignment and spatial normalization. We also perform basic denoising by removing global and multivariate spikes, average CSF activity, linear/quadratic trends, and 24 motion covariates (e.g., 6 centered realignment, their squares, derivative, and squared derivatives). We are very cautious about performing high-pass filtering as many of the effects we are interested in occur in [slower frequencies](https://www.biorxiv.org/content/early/2018/12/16/487892). We find that including average activity from a CSF mask helps a lot in reducing different types of physiological and motion related artifacts. We typically apply spatial smoothing, but depending on the question we don't always perform this step. For spatial feature selection, we rarely use searchlights and instead tend to use parcellations. This allows us to quickly prototype analysis ideas using smaller numbers of parcels (e.g., n=50) and then increase the number if we want greater spatial specificity. We usually use a [parcellation](https://neurovault.org/collections/2099/) that we developed based on meta-analytic coactivation using the neurosynth database. We have written a [paper](https://osf.io/4exrn/?show=view) about the costs and benefits of different spatial feature selection strategies. We have also evaluated the [efficacy](https://www.biorxiv.org/content/10.1101/2020.03.27.012310v1) of using [caseforge headcases](https://caseforge.co/?gclid=CjwKCAjw8df2BRA3EiwAvfZWaGA5Jz_RABlW6vKdvdjJCULwaeFW3BHMI-FkSLX27DbS4B7LlUHOrhoCYKIQAvD_BwE) in reducing head motion in naturalistic viewing studies. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T02:34:11.627082Z",
     "start_time": "2020-05-15T02:34:11.622577Z"
    }
   },
   "source": [
    "Have thoughts on preprocessing?  Please share them as a github [issue](https://github.com/naturalistic-data-analysis/naturalistic_data_analysis/issues) on our jupyter-book repository and we can incorporate them into the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
