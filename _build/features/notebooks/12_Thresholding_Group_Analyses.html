---
redirect_from:
  - "/features/notebooks/12-thresholding-group-analyses"
interact_link: content/features/notebooks/12_Thresholding_Group_Analyses.ipynb
kernel_name: conda-env-py36-py
kernel_path: content/features/notebooks
has_widgets: false
title: |-
  Thresholding Group Analyses
pagenum: 21
prev_page:
  url: /features/notebooks/11_Group_Analysis.html
next_page:
  url: /features/notebooks/13_Connectivity.html
suffix: .ipynb
search: false threshold fdr tests our voxels rate positives fwer p positive using signal any simulation correction multiple approach cluster e www simulations data png com bonferroni across need lets spatial thresholding alpha test q hypothesis different true control run extent fsl analyses fmri brain testing specific error voxel approaches overall controlling calculate values well effect power discovery images overview watch v practice distribution t value results only means seems also initial not particular requires h null between participants reject probability correcting proportion significant approximately contrast youtube thresholds okay independent family another such image much matthew brett github ac uk org

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Thresholding Group Analyses</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Thresholding-Group-Analyses">Thresholding Group Analyses<a class="anchor-link" href="#Thresholding-Group-Analyses"> </a></h1><p><em>Written by Luke Chang</em></p>
<p>The primary goal in fMRI data analysis is to make inferences about how the brain processes information. These inferences can be in the form of predictions, but most often we are testing hypotheses about whether a particular region of the brain is involved in a specific type of process. This requires rejecting a $H_0$ hypothesis (i.e., that there is no effect). Null hypothesis testing is traditionally performed by specifying contrasts between different conditions of an experimental design and assessing if these differences between conditions are reliably present across many participants. There are two main types of errors in null-hypothesis testing.</p>
<p><em>Type I error</em></p>
<ul>
<li>$H_0$ is true, but we mistakenly reject it (i.e., False Positive)</li>
<li>This is controlled by significance level $\alpha$.</li>
</ul>
<p><em>Type II error</em></p>
<ul>
<li>$H_0$ is false, but we fail to reject it (False Negative)</li>
</ul>
<p>The probability that a hypothesis test will correctly reject a false null hypothesis is described as the <em>power</em> of the test.</p>
<p>Hypothesis testing in fMRI is complicated by the fact that we are running many tests across each voxel in the brain (hundreds of thousands of tests). Selecting an appropriate threshold requires finding a balance between sensitivity (i.e., true positive rate) and specificity (i.e., false negative rate). There are two main approaches to correcting for multiple tests in fMRI data analysis. <em>Familywise Error Rate</em> (FWER) attempts to control the probability of finding <em>any</em> false positives. Mathematically, FWER can be defined as the probability $P$ of observing any false positive ${FWER} = P({False Positives}\geq 1)$. While, <em>False Discovery Rate</em> (FDR) attempts to control the proportion of false positives among rejected tests. Formally, this is the expected proportion of false positive to the observed number of significant tests ${FDR} = E(\frac{False Positives}{Significant Tests})$.</p>
<p>This should probably be no surprise to anyone, but fMRI studies are expensive and inherently underpowered. Here is a simulation by Jeannette Mumford to show approximately how many participants you would need to achieve 80% power assuming a specific effect size in your contrast.</p>
<p><img src="../../images/thresholding/fmri_power.png" alt="fmri_power.png"></p>
<p><strong>Videos</strong></p>
<p>For a more in depth overview, I encourage you to watch these videos on correcting for multiple tests by Martin Lindquist &amp; Tor Wager.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=AalIM9-5-Pk">Multiple Comparisons</a></li>
<li><a href="https://www.youtube.com/watch?v=MxQeEdVNihg">FWER</a></li>
<li><a href="https://www.youtube.com/watch?v=W9ogBO4GEzA">FDR</a></li>
<li><a href="https://www.youtube.com/watch?v=N7Iittt8HrU">Thresholds in Practice</a></li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Simulations">Simulations<a class="anchor-link" href="#Simulations"> </a></h2><p>Let's explore the concept of false positives to get an intuition about what the overall goals and issues are in controlling for multiple tests.</p>
<p>Let's load the modules we need for this tutorial. We are currently including the SimulateGrid class which contains everything we need to run all of the simulations. Eventually, this will be moved into the nltools package.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">nltools.data</span> <span class="k">import</span> <span class="n">Brain_Data</span>
<span class="kn">from</span> <span class="nn">nltools.simulator</span> <span class="k">import</span> <span class="n">SimulateGrid</span>

<span class="n">netid</span> <span class="o">=</span> <span class="s1">&#39;f00275v&#39;</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">&#39;/dartfs/rc/lab/P/Psych60/students_output/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">netid</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;/dartfs/rc/lab/P/Psych60/data/brainomics_data/&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Okay, let's get started and generate 100 x 100 voxels from $\mathcal{N}(0,1)$ distribution for 20 independent participants. We will run a one sample t-test on each voxel over participants.</p>
<p>Now let's apply a threshold. We can specify thresholds at a specific t-value using the <code>threshold_type='t'</code>. Alternatively, we can specify a specific p-value using the <code>threshold_type='p'</code>. To calculate the number of false positives, we can simply count the number of tests that exceed this threshold.</p>
<p>If we run this simulation again 100 times, we can estimate the false positive rate, which is the average number of times we observe any false positives over all of the simulations.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_4_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So this particular threshold (i.e., p &lt; 0.05) results in observing at least one false positive across every one of our simulations.</p>
<p>What if we looked at a fewer number of voxels? How would this change our false positive rate?</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_6_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This simulation shows that examining fewer numbers of voxels will yield considerably less false positives. One common approach to controlling for multiple tests involves only looking for voxels with a specific region (e.g., small volume correction), or looking at average activation within a larger region (e.g., ROI based analyses).</p>
<p>What about if we increase the threshold on our original 100 x 100 grid?</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">0001</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_8_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can see that this dramatically decreases the number of false positives to the point that some of the simulations no longer contain any false positives.</p>
<p>What is the optimal threshold that will give us an $\alpha=0.05$?</p>
<p>To calculate this, we will run 100 simulations at different threshold levels to find the threshold that leads to a false positive rate that is lower than our alpha value.</p>
<p>We could search over t-values, or p-values. Let's explore t-values first.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">n_simulations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">)</span>

<span class="n">sim_all</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
    <span class="n">sim</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run_multiple_simulations</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="n">n_simulations</span><span class="p">)</span>
    <span class="n">sim_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">fpr</span><span class="p">)</span>

<span class="n">f</span><span class="p">,</span><span class="n">a</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">a</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sim_all</span><span class="p">))</span>
<span class="n">a</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">a</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Threshold (t)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">a</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Simulations = </span><span class="si">{n_simulations}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">a</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.lines.Line2D at 0x1219de128&gt;</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_10_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see, the false positive rate is close to our alpha starting at a threshold of about 6.2. This means that when we test a hypothesis over 10,000 independent voxels, we can be confident that we will only observe false positives in approximately 5 out of 100 experiments. This means that we are effectively controlling the family wise error rate (FWER).</p>
<p>Let's use that threshold for our simulation again.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">6.2</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_12_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another way to find the threshold that controls FWER is to divide the alpha by the number of independent tests across voxels. This is called bonferroni correction.</p>
<p>${bonferroni} = \frac{\alpha}{M}$, where $M$ is the number of voxels.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_width</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.05</span><span class="o">/</span><span class="p">(</span><span class="n">grid_width</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="n">grid_width</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_14_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This seems like a great way to ensure that we minimize our false positives.</p>
<p>Now what happens when start adding signal to our simulation?</p>
<p>We will represent signal in a smaller square in the middle of the simulation. The width of the square can be changed using the <code>signal_width</code> parameter. The amplitude of this signal is controlled by the <code>signal_amplitude</code> parameter.</p>
<p>Let's see how well the bonferroni threshold performs when we add 100 voxels of signal.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_width</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="o">/</span><span class="p">(</span><span class="n">grid_width</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">signal_width</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">signal_amplitude</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">signal_amplitude</span><span class="o">=</span><span class="n">signal_amplitude</span><span class="p">,</span> <span class="n">signal_width</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">grid_width</span><span class="o">=</span><span class="n">grid_width</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_16_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we show how many voxels were identified using the bonferroni correction. We can see that we have an effective false positive rate approximately equal to our alpha threshold. However, our threshold is so high, that we can barely detect any true signal with this amplitude. In fact, we are only recovering about 12% of the voxels that should have signal.</p>
<p>This simulation highlights the main issue with using bonferroni correction in practice. The threshold is so conservative that the magnitude of an effect needs to be unreasonably large to survive correction over hundreds of thousands of voxels.</p>
<p>How well does the bonferroni threshold perform at different signal intensities?  Try playing with different signal amplitudes.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_width</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="o">/</span><span class="p">(</span><span class="n">grid_width</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">signal_amplitude</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">signal_amplitude</span><span class="o">=</span><span class="n">signal_amplitude</span><span class="p">,</span> <span class="n">signal_width</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">grid_width</span><span class="o">=</span><span class="n">grid_width</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_18_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok, clearly we can see that the bonferroni threshold is too conservative for this example. We need to double the magnitude of the effect before we can reliably recover most of the signal.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Family-Wise-Error-Rate">Family Wise Error Rate<a class="anchor-link" href="#Family-Wise-Error-Rate"> </a></h2><p>At this point you may be wondering if it even makes sense to assume that each test is independent. It seems reasonable to expect some degree of spatial correlation in our data. Our simulation is a good example of this as we have a square that contains signal across contiguous voxels. In practice, most of our functional neuroanatomy that we are investigating is larger than a single voxel and in addition, we are smoothing the data in preprocessing, which also increases spatial correlation.</p>
<p>It can be shown that the Bonferroni correction is overally conservative in the presence of spatial dependence and results in a decreased power to detect voxels that are truly active.</p>
<h3 id="Cluster-Extent">Cluster Extent<a class="anchor-link" href="#Cluster-Extent"> </a></h3><p>Another approach to controlling the FWER is called cluster correction, or cluster extent. In this approach, the goal is to identify a threshold such that the maximum statistic exceeds it at a specified alpha. The distribution of the maximum statistic can be approximated using Gaussian Random Field Theory (RFT), which attempts to account for the spatial dependence of the data.</p>
<p><img src="../../images/thresholding/fwer.png" alt="fwer.png"></p>
<p>This requires specifying an initial threshold to determine the <em>Euler Characteristic</em> or the number of blobs minus the number of holes in the thresholded image. The number of voxels in the blob and the overall smoothness can be used to calculate something called <em>resels</em> or resolution elements and can be effectively thought of as the spatial units that need to be controlled for using FWER. We won't be going into too much detail with this approach as the mathematical details are somewhat complicated. In practice, if the image is smooth and the number of subjects is high enough (around 20), cluster correction seems to provide control closer to the true false positive rate than Bonferroni correction. Though we won't be spending time simulating this today, I encourage you to check out this Python <a href="https://matthew-brett.github.io/teaching/random_fields.html">simulation</a> by Matthew Brett and this <a href="https://www.fil.ion.ucl.ac.uk/spm/doc/books/hbf2/pdfs/Ch14.pdf">chapter</a> for an introduction to random field theory.</p>
<p><img src="../../images/thresholding/grf.png" alt="grf.png"></p>
<p>Cluster extent thresholding has recently become somewhat controversial due to several high profile papers that have found that it appears to lead to an inflated false positive rate in practice (see <a href="https://www.pnas.org/content/113/28/7900">Ekland et al., 2017</a>). A recent analyses by <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4214144/">Woo et al. 2014</a> has shown that a liberal initial threshold (i.e. higher than p &lt; 0.001) will inflate the number of false positives above the nominal level of 5%. There is no optimal way to select the initial threshold and often slight changes will give very different results. Furthermore, this approach does not appear to work equally well across all types of findings. For example, this approach can work well with some amounts of smoothing results that have a particular spatial extent, but not equally well for all types of signals. In other words, it seems potentially problematic to assume that spatial smoothness is constant over the brain and also that it is adequately represented using a Gaussian distribution. Finally, it is important to note that this approach only allows us to make inferences for the entire cluster. We can say that there is some voxel in the cluster that is significant, but we can't really pinpoint which voxels within the cluster may be driving the effect.</p>
<p>There are several other popular FWER approaches to correcting for multiple tests that try to address these issues.</p>
<h4 id="Threshold-Free-Cluster-Extent">Threshold Free Cluster Extent<a class="anchor-link" href="#Threshold-Free-Cluster-Extent"> </a></h4><p>One interesting solution to the issue of finding an initial threshold seems to be addressed by the threshold free cluster enhancement method presented in <a href="https://www.sciencedirect.com/science/article/pii/S1053811908002978?via%3Dihub">Smith &amp; Nichols, 2009</a>. In this approach, the authors propose a way to combine cluster extent and voxel height into a single metric that does not require specifying a specific initial threshold. It essentially involves calculating the integral of the overall product of a signal intensity and spatial extent over multiple thresholds. It has been shown to perform particularly well with combined with non-parameteric resampling approaches such as <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise/UserGuide">randomise</a> in FSL. This method is implemented in FSL and also in <a href="https://github.com/markallenthornton/MatlabTFCE">Matlab</a> by Mark Thornton. For more details about this approach check out this <a href="http://markallenthornton.com/blog/matlab-tfce/">blog post</a> by Mark Thornton, this <a href="https://mumfordbrainstats.tumblr.com/post/130127249926/paper-overview-threshold-free-cluster-enhancement">video</a> by Jeanette Mumford, and the original <a href="https://www.fmrib.ox.ac.uk/datasets/techrep/tr08ss1/tr08ss1.pdf">technical report</a>.</p>
<h4 id="Parametric-simulations">Parametric simulations<a class="anchor-link" href="#Parametric-simulations"> </a></h4><p>One approach to estimating the inherent smoothness in the data spatial autocorrelation is using parametric simulations this was the approach originally adopted in AFNI's AlphaSim/3DClustSim. After it was <a href="https://www.pnas.org/content/113/28/7900">demonstrated</a> that real fMRI data was not adequately modeled by a standard Gaussian distribution, the AFNI group quickly updated their software and implemented a range of different algorithms in their <a href="https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dClustSim.html">3DClustSim</a> tool.  See this <a href="https://www.biorxiv.org/content/10.1101/065862v1">paper</a> for an overview of these changes.</p>
<h3 id="Nonparametric-approaches">Nonparametric approaches<a class="anchor-link" href="#Nonparametric-approaches"> </a></h3><p>As an alternative to RFT, nonparametric methods use the data themselves to find the appropriate distribution. These methods can provide substantial improvements in power and validity, particularly with small sample sizes, so we regard them as the ‘gold standard’ in imaging analyses. Thus these tests can verify the validity of the less computationally expensive parametric approaches. The FSL tool <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise/UserGuide">randomise</a>, is probably the current gold standard and there are versions that run on GPUs, such as <a href="https://github.com/wanderine/BROCCOLI">BROCCOLI</a> to speed up the computation time.</p>
<p>Here we will run a simulation using a one-sample permutation test (i.e., sign test) on our data. We will make the grid much smaller to speed up the simulation. This approach makes no distributional assumptions, but still requires correcting for multiple tests using either FWER or FDR approaches.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_width</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span>
<span class="n">signal_amplitude</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">signal_amplitude</span><span class="o">=</span><span class="n">signal_amplitude</span><span class="p">,</span> <span class="n">signal_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">grid_width</span><span class="o">=</span><span class="n">grid_width</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">t_values</span><span class="p">,</span> <span class="n">simulation</span><span class="o">.</span><span class="n">p_values</span> <span class="o">=</span> <span class="n">simulation</span><span class="o">.</span><span class="n">_run_permutation</span><span class="p">(</span><span class="n">simulation</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">isfit</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">threshold_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="s1">&#39;p&#39;</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_21_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="False-Discovery-Rate">False Discovery Rate<a class="anchor-link" href="#False-Discovery-Rate"> </a></h2><p>You may be wondering why we need to control for <em>any</em> false positive when testing across hundreds of thousands of voxels. Surely a few are okay as long as they don't overwhelm the true signal. The <em>false discovery rate</em> (FDR) is a more recent development in multiple testing correction originally described by <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1995.tb02031.x">Benjamini &amp; Hochberg, 1995</a>. While FWER is the probability of any false positives occurring in a family of tests, the FDR is the expected proportion of false positives among significant tests.</p>
<p>The FDR is fairly straightforward to calculate.</p>
<ol>
<li>We select a desired limit $q$ on FDR, which is the proportion of false positives we are okay with observing (e.g., 5/100 tests or 0.05).</li>
<li>We rank all of the p-values over all the voxels from the smallest to largest. </li>
<li>We find the threshold $r$ such that $p \leq i/m * q$</li>
<li>We reject any $H_0$ that is lower than $r$.</li>
</ol>
<p><img src="../../images/thresholding/fdr_calc.png" alt="image.png"></p>
<p>In a brain map, this means that we expect approximately 95% of the voxels reported at q &lt; .05 FDR-corrected to be true activations (note we use q instead of p). The FDR procedure adaptively identifies a threshold based on the overall signal across all voxels. Larger signals results in lower thresholds. Importantly, if all of the null hypotheses are true, then the FDR will be equivalent to the FWER. This means that any FWER procedure will <em>also</em> control the FDR. For these reasons, any procedure which controls the FDR is necessarily less stringent than a FWER controlling procedure, which leads to an overall increased power. Another nice feature of FDR, is that it operates on p-values instead of test statistics, which means it can be applied to most statistical tests.</p>
<p>This figure is taken from Poldrack, Mumford, &amp; Nichols (2011) and compares different procedures to control for multiple tests.
<img src="../../images/thresholding/fdr.png" alt="image.png"></p>
<p>For a more indepth overview of FDR, see this <a href="https://matthew-brett.github.io/teaching/fdr.html">tutorial</a> by Matthew Brett.</p>
<p>Let's now try to apply FDR to our own simulations. All we need to do is add a <code>correction='fdr'</code> flag to our simulation plot. We need to make sure that the <code>threshold=0.05</code> to use the correct $q$.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_width</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span>
<span class="n">signal_amplitude</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">signal_amplitude</span><span class="o">=</span><span class="n">signal_amplitude</span><span class="p">,</span> <span class="n">signal_width</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">grid_width</span><span class="o">=</span><span class="n">grid_width</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;q&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="s1">&#39;fdr&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;FDR q &lt; 0.05 corresponds to p-value of </span><span class="si">{simulation.corrected_threshold}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>FDR q &lt; 0.05 corresponds to p-value of 0.0002805301468049594
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_23_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Okay, using FDR of q &lt; 0.05 for our simulation identifies a p-value threshold of p &lt; 0.00034. This is more liberal than the bonferroni threshold of p &lt; 0.000005 and allows us to recover much more signal as a consequence. You can see that at this threshold there are more false positives, which leads to a much higher overall false positive rate. Remember, this metric is only used for calculating the family wise error rate and indicates the presence of <em>any</em> false positive across each of our 100 simulations.</p>
<p>To calculate the empirical false discovery rate, we need to calculate the percent of any activated voxels that were false positives.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">simulation</span><span class="o">.</span><span class="n">multiple_fdr</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Discovery Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Discovery Rate of Simulations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5, 0, &#39;False Discovery Rate of Simulations&#39;)</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_25_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In our 100 simulations this is below our q &lt; 0.05.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Thresholding-Brain-Maps">Thresholding Brain Maps<a class="anchor-link" href="#Thresholding-Brain-Maps"> </a></h2><p>Today we will be exploring two simple and fast ways to threshold your group analyses.</p>
<p>First, we will simply threshold based on selecting an arbitrary statistical threshold. The values are completely arbitrary, but it is common to start with something like p &lt; .001. We call this <em>uncorrected</em> because this is simply the threshold for any voxel as we are not controlling for multiple tests.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">con1_name</span> <span class="o">=</span> <span class="s1">&#39;horizontal_checkerboard&#39;</span>
<span class="n">con1_file_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;S*_</span><span class="si">{con1_name}</span><span class="s1">*nii.gz&#39;</span><span class="p">))</span>
<span class="n">con1_file_list</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">con1_dat</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">con1_file_list</span><span class="p">)</span>
<span class="n">con1_stats</span> <span class="o">=</span> <span class="n">con1_dat</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">threshold_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;unc&#39;</span><span class="p">:</span><span class="o">.</span><span class="mi">001</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/dartfs-hpc/rc/home/v/f00275v/.conda/envs/Psych60_py36/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater
  return (self.a &lt; x) &amp; (x &lt; self.b)
/dartfs-hpc/rc/home/v/f00275v/.conda/envs/Psych60_py36/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less
  return (self.a &lt; x) &amp; (x &lt; self.b)
/dartfs-hpc/rc/home/v/f00275v/.conda/envs/Psych60_py36/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 &amp; (x &lt;= self.a)
/dartfs-hpc/rc/home/v/f00275v/.conda/envs/Psych60_py36/lib/python3.6/site-packages/nltools/stats.py:171: RuntimeWarning: invalid value encountered in less
  mask.data = (mask.data &lt; thr).astype(int)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span><span class="o">=</span> <span class="n">con1_stats</span><span class="p">[</span><span class="s1">&#39;thr_t&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_29_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also easily run FDR correction by changing the inputs of the <code>threshold_dict</code>. We will be using a q value of 0.05 to control our false discovery rate.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">con1_stats</span> <span class="o">=</span> <span class="n">con1_dat</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">threshold_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fdr&#39;</span><span class="p">:</span><span class="o">.</span><span class="mi">05</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater
  return (self.a &lt; x) &amp; (x &lt; self.b)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less
  return (self.a &lt; x) &amp; (x &lt; self.b)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 &amp; (x &lt;= self.a)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/nltools/stats.py:118: RuntimeWarning: invalid value encountered in less_equal
  below = np.where(s &lt;= null)[0]
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/nltools/stats.py:171: RuntimeWarning: invalid value encountered in less
  mask.data = (mask.data &lt; thr).astype(int)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">con1_stats</span><span class="p">[</span><span class="s1">&#39;thr_t&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_32_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can see that at least for this particular contrast, the FDR threshold appears to be more liberal than p &lt; 0.001 uncorrected.</p>
<p>Let's look at another contrast between vertical and horizontal checkerboards.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">con2_name</span> <span class="o">=</span> <span class="s1">&#39;vertical_checkerboard&#39;</span>
<span class="n">con2_file_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;S*_</span><span class="si">{con2_name}</span><span class="s1">*nii.gz&#39;</span><span class="p">))</span>
<span class="n">con2_file_list</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">con2_dat</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">con2_file_list</span><span class="p">)</span>

<span class="n">con1_v_con2</span> <span class="o">=</span> <span class="n">con1_dat</span><span class="o">-</span><span class="n">con2_dat</span>

<span class="n">con1_v_con2_stats</span> <span class="o">=</span> <span class="n">con1_v_con2</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">threshold_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fdr&#39;</span><span class="p">:</span><span class="o">.</span><span class="mi">05</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/dartfs-hpc/rc/home/v/f00275v/.conda/envs/Psych60_py36/lib/python3.6/site-packages/nltools/stats.py:118: RuntimeWarning: invalid value encountered in less_equal
  below = np.where(s &lt;= null)[0]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">con1_v_con2_stats</span><span class="p">[</span><span class="s1">&#39;thr_t&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/dartfs-hpc/rc/home/v/f00275v/.conda/envs/Psych60_py36/lib/python3.6/site-packages/nilearn/plotting/displays.py:767: UserWarning: empty mask
  get_mask_bounds(new_img_like(img, not_mask, affine))
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/12_Thresholding_Group_Analyses_35_2.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It doesn't look like anything survives this contrast using the correction for multiple tests.</p>
<p>This concludes are very quick overview to performing univariate analyses in fMRI data analysis.</p>
<p>We will continue to add more advanced tutorials to the dartbrains.org website. Stay tuned!</p>

</div>
</div>
</div>
</div>

 


    </main>
    