---
redirect_from:
  - "/features/notebooks/4-ica"
interact_link: content/features/notebooks/4_ICA.ipynb
kernel_name: python3
kernel_path: content/features/notebooks
has_widgets: false
title: |-
  Separating Signal from Noise with ICA
pagenum: 13
prev_page:
  url: /features/markdown/Signal_Measurement.html
next_page:
  url: /features/notebooks/5_Introduction_to_Neuroimaging_Data.html
suffix: .ipynb
search: data run ica preprocessing using signals our might fmriprep component docker also signal s license frequency components noise recommend readthedocs io en stable dropbox dartbrains work standard any threshold tutorial explore artifacts participant html specific users lukechang its into bids nltools filter hz spatial analysis axis voxels sure plot timecourse present already done loading automated pipeline stanford poldracklab com latest location want fs file issues freesurfer even not validator very once ok load steps high pass scanner arbitrary voxel independent decompose fastica scikit learn setting images default possible view brain deviations less play nyquist respiration cardiac important consider think does

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Separating Signal from Noise with ICA</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Identifying-Signal-and-Noise-Using-ICA">Identifying Signal and Noise Using ICA<a class="anchor-link" href="#Identifying-Signal-and-Noise-Using-ICA"> </a></h1><p><em>Written by Luke Chang</em></p>
<p>In this tutorial we will use ICA to explore which signals in our imaging data might be real signal or artifacts.</p>
<p>For a brief overview of types of artifacts that might be present in your data, I recommend watching this video by Tor Wager and Martin Lindquist.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>

<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;7Kk_RsGycHs&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/7Kk_RsGycHs"
    frameborder="0"
    allowfullscreen
></iframe>

</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocessing-Data">Preprocessing Data<a class="anchor-link" href="#Preprocessing-Data"> </a></h2><p>To run this tutorial, you must have run preprocessing on at least one participant. <em>If you are in Psych60, this has already been done for you and you can just skip to <strong>Loading Data</strong></em>. If you reading this online, then I recommend preprocessing your data with <a href="https://fmriprep.readthedocs.io/en/stable/">fmriprep</a>, which is a robust, but opinionated automated preprocessing pipeline developed by <a href="https://poldracklab.stanford.edu/">Russ Poldrack's group at Stanford University</a>. The developer's have made a number of choices about how to preprocess your fMRI data using best practices and have created an automated pipeline using multiple software packages that are all distributed via a <a href="https://fmriprep.readthedocs.io/en/stable/docker.html">docker container</a>.</p>
<p>In theory, this is extraodinarily straightforward to run:</p>
<ul>
<li><ol>
<li><p>Install <a href="https://www.docker.com/">Docker</a> and download image</p>
<p><code>docker pull poldracklab/fmriprep:&lt;latest-version&gt;</code></p>
</li>
</ol>
</li>
</ul>
<ul>
<li><ol>
<li><p>Run a single command in the terminal specifying the location of the data, the location of the output, the participant id, and a few specific flags depending on specific details of how you want to run the preprocessing.</p>
<p><code>fmriprep-docker /Users/lukechang/Dropbox/Dartbrains/Data/localizer /Users/lukechang/Dropbox/Dartbrains/Data/preproc participant --participant_label sub-S01 --write-graph --fs-no-reconall --notrack --fs-license-file ~/Dropbox/Dartbrains/License/license.txt --work-dir /Users/lukechang/Dropbox/Dartbrains/Data/work</code></p>
</li>
</ol>
</li>
</ul>
<p>In practice, it's alway a little bit finicky to get everything set up on a particular system. Sometimes you might run into issues with a specific missing file like the <a href="https://fmriprep.readthedocs.io/en/stable/usage.html#the-freesurfer-license">freesurfer license</a> even if you're not using it. You might also run into issues with the format of the data that might have some conflicts with the <a href="https://github.com/bids-standard/bids-validator">bids-validator</a>. In our experience, there is always some frustrations getting this to work, but it's very nice once it's done.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-Data">Loading Data<a class="anchor-link" href="#Loading-Data"> </a></h2><p>Ok, once you've finished preprocessing some of your data with fmriprep, we can load a subject and run an ICA to explore signals that are present. Since we have completed preprocessing, our data should be realigned and also normalized to MNI stereotactic space. We will use the <a href="https://neurolearn.readthedocs.io/en/latest/">nltools</a> package to work with this data in python.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">nltools.data</span> <span class="kn">import</span> <span class="n">Brain_Data</span>
<span class="kn">from</span> <span class="nn">nltools.plotting</span> <span class="kn">import</span> <span class="n">component_viewer</span>

<span class="n">base_dir</span> <span class="o">=</span> <span class="s1">&#39;../data/localizer/derivatives/preproc/fmriprep&#39;</span>
<span class="n">base_dir</span> <span class="o">=</span> <span class="s1">&#39;/Users/lukechang/Dropbox/Dartbrains/Data/preproc/fmriprep&#39;</span>
<span class="n">sub</span> <span class="o">=</span> <span class="s1">&#39;S01&#39;</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;sub-</span><span class="si">{</span><span class="n">sub</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span><span class="s1">&#39;func&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;sub-</span><span class="si">{</span><span class="n">sub</span><span class="si">}</span><span class="s1">_task-localizer_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="More-Preprocessing">More Preprocessing<a class="anchor-link" href="#More-Preprocessing"> </a></h2><p>Even though, we have technically already run most of the preprocessing there are a couple of more steps that will help make the ICA cleaner.</p>
<p>First, we will run a high pass filter to remove any low frequency scanner drift. We will pick a fairly arbitrary filter size of 0.0078hz (1/128s). We will also run spatial smoothing with a 6mm FWHM gaussian kernel to increase a signal to noise ratio at each voxel. These steps are very easy to run using nltools after the data has been loaded.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">sampling_freq</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mf">2.4</span><span class="p">,</span> <span class="n">high_pass</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">128</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">smooth</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Independent-Component-Analysis-(ICA)">Independent Component Analysis (ICA)<a class="anchor-link" href="#Independent-Component-Analysis-(ICA)"> </a></h2><p>Ok, we are finally ready to run an ICA analysis on our data.</p>
<p>ICA attempts to perform blind source separation by decomposing a multivariate signal into additive subcomponents that are maximally independent.</p>
<p>We will be using the <code>decompose()</code> method on our <code>Brain_Data</code> instance. This runs the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.fastica.html">FastICA</a> algorithm implemented by scikit-learn. You can choose whether you want to run spatial ICA by setting <code>axis='voxels</code> or temporal ICA by setting <code>axis='images'</code>. We also recommend running the whitening flat <code>whiten=True</code>. By default <code>decompose</code> will estimate the maximum components that are possible given the data. We recommend using a completely arbitrary heuristic of 20-30 components.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr</span> <span class="o">=</span> <span class="mf">2.4</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">decompose</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ica&#39;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;images&#39;</span><span class="p">,</span> <span class="n">whiten</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Viewing-Components">Viewing Components<a class="anchor-link" href="#Viewing-Components"> </a></h1><p>We will use the interactive <code>component_viewer</code> from nltools to explore the results of the analysis. This viewer uses ipywidgets to select the <code>Component</code> to view and also the threshold. You can manually enter a component number to view or scroll up and down.</p>
<p>Components have been standardized, this allows us to threshold the brain in terms of standard deviations. For example, the default threshold of 2.0, means that any voxel that loads on the component greater or less than 2 standard deviations will be overlaid on the standard brain. You can play with different thresholds to be more or less inclusive - a threshold of 0 will overlay all of the voxels. If you play with any of the numbers, make sure you press tab to update the plot.</p>
<p>The second plot is the time course of the voxels that load on the component. The x-axis is in TRs, which for this dataset is 2.4 sec.</p>
<p>The third plot is the powerspectrum of the timecourse. There is not a large range of possible values as we can only observe signals at the nyquist frequency, which is half of our sampling frequency of 1/2.4s (approximately 0.21hz) to a lower bound of 0.0078hz based on our high pass filter. There might be systematic oscillatory signals. Remember, that signals that oscillate a faster frequency than the nyquist frequency will be aliased. This includes physiological artifacts such as respiration and cardiac signals.</p>
<p>It is important to note that ICA cannot resolve the sign of the component. So make sure you consider signals that are positive as well as negative.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">component_viewer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">tr</span><span class="o">=</span><span class="mf">2.4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="564c5fca-ec05-45b3-8a93-4c154740fef4"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#564c5fca-ec05-45b3-8a93-4c154740fef4');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "24a0e738864b4269bbb4ac97e2a1b3e4", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="../../images/ica/ica_viewer_demo.gif" alt=""></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Exercises">Exercises<a class="anchor-link" href="#Exercises"> </a></h1><p>For this tutorial, try to guess which components are signal and which are noise. Also, be sure to label the type of noise you think you might be seeing (e.g., head motion, scanner spikes, cardiac, respiration, etc.) Do this for subjects <code>s01</code> and <code>s02</code>.</p>
<p>What features do you think are important to consider when making this judgment?  Does the spatial map provide any useful information? What about the timecourse of the component? Does it map on to the plausible timecourse of the task.What about the power spectrum?</p>

</div>
</div>
</div>
</div>

 


    </main>
    